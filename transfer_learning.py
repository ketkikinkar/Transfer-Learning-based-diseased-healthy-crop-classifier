# -*- coding: utf-8 -*-
"""Transfer_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15KCWLQIL_0p6f7S-YhZq_dJdhdvZu_Dm

Transfer-Learning based diseased / healthy crop classifier (Potato , Pepper ,  Tomato)

Importing Required Libraries
"""

#For generating neural network / nodes
from keras.layers import Input, Lambda, Dense, Flatten
#For Initializing the model
from keras.models import Model
#For defining the architecture Employed
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
#For pre-processing and Image Augmentation
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
#For enabling Sequential Layer
from keras.models import Sequential
#For files reterival and path
from glob import glob
#For visualization
import matplotlib.pyplot as plt

#Pre-defining the Image Size
IMAGE_SIZE = [224, 224]

#Mounting Google drive path
train_path = '/content/drive/My Drive/Data-Set/Train'
valid_path = '/content/drive/My Drive/Data-Set/Test/Test'

# add preprocessing layer to the front of VGG
vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

#Disabling Weight Training
for layer in vgg.layers:
  layer.trainable = False

#Variable for storing number of files
folders = glob('/content/drive/My Drive/Data-Set/Test/Test/*')
print(len(folders))
  

# New dense layer added (Most imp step )
x = Flatten()(vgg.output)

# x = Dense(1000, activation='relu')(x)
prediction = folders), Dense(len(activation='softmax')(x)

# creating a model 
model = Model(inputs=vgg.input, outputs=prediction)

# Preview of Structure
model.summary()

# Defining Loss function and optimizer to be used
model.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)

# Data Augmentation
from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)

# Uniforming the datagen
test_datagen = ImageDataGenerator(rescale = 1./255)

# Training Set
training_set = train_datagen.flow_from_directory(train_path,
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'categorical')
# Test Set
test_set = test_datagen.flow_from_directory(valid_path,
                                            target_size = (224, 224),
                                            batch_size = 32,
                                            class_mode = 'categorical')

# fit the model
r = model.fit_generator(
  training_set,
  validation_data=test_set,
  epochs=5,
  steps_per_epoch=len(training_set),
  validation_steps=len(test_set)
)

import tensorflow as tf

from keras.models import load_model
        
model.save('Transfer_Learning_01.h5')